 =====摄像头结构和工作原理=====
拍摄景物通过镜头，将生成的光学图像投射到传感器上，然后光学图像被转换成电信号，电信号再经过模数转换变为数字信号，数字信号经过DSP加工处理，再被送到电脑中进行处理，最终转换成手机屏幕上能够看到的图像。
数字信号处理芯片DSP(DIGITAL SIGNAL PROCESSING)功能：主要是通过一系列复杂的数学算法运算，对数字图像信号参数进行优化处理，并把处理后的信号通过USB等接口传到PC等设备。DSP结构框架:
      1. ISP(image signal processor)(镜像信号处理器)
      2. JPEG encoder(JPEG图像解码器)
      3. USB device controller(USB设备控制器)
常见的摄像头传感器类型主要有两种，
      一种是CCD传感器（Chagre Couled Device），即电荷耦合器。
      一种是CMOS传感器（Complementary Metal-Oxide Semiconductor）即互补性金属氧化物半导体。
CCD 的优势在于成像质量好，但是制造工艺复杂，成本高昂，且耗电高。在相同分辨率下，CMOS价格比CCD便宜，但图像质量相比CCD来说要低一些。CMOS 影像传感器相对CCD具有耗电低的优势，加上随着工艺技术的进步，CMOS的画质水平也不断地在提高，所以目前市面上的手机摄像头都采用CMOS传感器。

手机摄像头的简单结构
滤光片有两大功用:
       1.滤除红外线。滤除对可见光有干扰的红外光，使成像效果更清晰。
       2.修整进来的光线。感光芯片由感光体(CELL)构成,最好的光线是直射进来,但为了怕干扰到邻近感光体,就需要对光线加以修整,因此那片滤光片不是 玻璃,而是石英片,利用石英的物理偏光特性,把进来的光线,保留直射部份,反射掉斜射部份,避免去影响旁边的感光点.
 
====相关参数和名词====
===常见图像格式===
       RGB格式：
       传统的红绿蓝格式，比如RGB565，RGB888，其16-bit数据格式为5-bit R + 6-bit G + 5-bit B。G多一位，原因是人眼对绿色比较敏感。
        YUV格式：
        luma (Y) + chroma (UV) 格式。YUV是指亮度参量和色度参量分开表示的像素格式，而这样分开的好处就是不但可以避免相互干扰，还可以降低色度的采样率而不会对图像质量影响太大。YUV是一个比较笼统地说法，针对它的具体排列方式，可以分为很多种具体的格式。
色度(UV)定义了颜色的两个方面─色调与饱和度，分别用CB和CR表示。其中，Cr反映了RGB输入信号红色部分与RGB信号亮度值之间的差异。而Cb反映的是RGB输入信号蓝色部分与RGB信号亮度值之间的差异。
主要的采样格式有YCbCr 4:2:0、YCbCr 4:2:2、YCbCr 4:1:1和 YCbCr 4:4:4。
RAW data格式：
    RAW图像就是CMOS或者CCD图像感应器将捕捉到的光源信号转化为数字信号的原始数据。RAW文件是一种记录了数码相机传感器的原始信息，同时记录了 由相机拍摄所产生的一些元数据（Metadata，如ISO的设置、快门速度、光圈值、白平衡等）的文件。RAW是未经处理、也未经压缩的格式，可以把 RAW概念化为“原始图像编码数据”或更形象的称为“数字底片”。sensor的每一像素对应一个彩色滤光片，滤光片按Bayer pattern分布。将每一个像素的数据直接输出，即RAW RGB data
Raw data（Raw RGB）经过彩色插值就变成RGB.

===相关技术指标===
    图像解析度/分辨率(Resolution)：
        QXGA （2048 X 1536）又称300万像素 
        UXGA （1600X 1200）又称200万像素 
        SXGA(1280 x1024)又称130万像素
        XGA(1024 x768)又称80万像素
        SVGA(800 x600)又称50万像素
  图像压缩方式：
       JPEG/M-JPEG
       H.261/H.263
       MPEG
       H.264 
===MIP接口介绍===
MIPI=Mobile Industry Processor Interface, 是类似SMIA的一个LVDS的一种接口，主要用在手机Camera Module上居多。 
就CameraModule而言，现在Micorn和OV均推出支持MIPI接口的Sensor。如Micorn的MT9D112，MT9T111和 OV的OV2650等，对于低像素的Sensor似乎MIPI的优势不是很明显哦，但是在3MP以上就可能有些优势了。 
       优势-1，Camera的布线大大减少。并口的数据接口，如果是YUV输出至少为8个数据Bit、2个Clock(MCLK和PCLK)、I2C两个、同步信号2个，再加地和电源等，如果换成MIPI的串口，可以减少2个同步信号，8个数据Bit变为DOUT_P、DOUT_N、CLK_P、 CLK_N，PCLK也可以不要，着实少了很多，布线自然方便许多。 
       优势-2，Noise的减少。走线越多被干扰的可能就越多，走线少了于是干扰就少了，同时MIPI信号是DOUT_N和DOUT_P成对走线，需要考虑 impedance，两根线从波形看是成反相，所以有外部干扰过来，就会被抵消很大部分，同时MIPI的信号属于LVDS(Low Voltage Differential Signaling：低压差分信号传输)底到MV的等级，于是他本身对于外部的干扰也是很小的。 
       优势-3，传输速度极快，从并口到串口，当然要足够大的速度，MIPI的理论上的速度可以到80MB/s-1GB/s，实际也在600-800MB/s，而传统的并口再高也不过600MB/s了吧。 
       优势-4，功耗低。并口的Camera，只要上电，给Clock于是PCLK就有输出，Data也会由输出，抓不到同步就成不了像，但是数据还是输出，于是就要功耗。而MIPI理a论上静态是没有功耗的。 

====高通的CAMERA部分硬件架构====
 
CAMERA部分硬件架构
VFE：VIDEO front-end 视频前端
VPE：Video preprocessing1  camera基本代码架构
高通平台对于camera的代码组织，大体上还是遵循Android的框架：即上层应用和HAL层交互，高通平台在HAL层里面实现自己的一套管理策略； 在kernel中实现sensor的底层驱动。但是，对于最核心的sensor端的底层设置、ISP效果相关等代码则是单独进行了抽离，放在了一个 
由于高通把大部分具体的设置及参数放到了daemon进程中，所以在kernel部分只是进行了V4L2的设备注册、IIC设备注册等简单的动作：

1.VFE的功能：
    1.1 通过算法提高图像的质量。
    1.2 提供高分辨率的图像的AWB(自动白平衡)/AE(自动曝光)/AF(自动对焦)算法处理。
    1.3 图像衰减校正。
    1.4 低光下的噪声滤波。
    1.5 图像色彩效果优化。
    1.6 皮肤颜色效果优化。
    1.7 图像抖动计算。
    1.8 亮度适应算法。
2.VPE的功能：
    2.1 图像稳定性。
    2.2 数字对焦。
    2.3 图像旋转。
    2.4 Overlay。

====android系统camera基本架构====
===应用层===
Camera 的 应用层在Android 上表现为直接调用SDK API 开发的一个Camera 应用APK 包。代码在/android/packages/apps/Camera 下。主要对 android.hardware.Camera（在Framework中） 类的调用，并且实现Camera 应用的业务逻辑和UI 显示。一个Android 应用中若要使用这个android.hardware.Camera 类，需要在Manifest 文件声明Camera 的权限，另外还 需要添加一些<uses-feature> 元素来声明应用中的Camera 特性，如自动对焦等。 具体做法可如下：
       <uses-permission android:name = "android.permission.CAMERA" />
       <uses-feature android:name = "android.hardware.camera" />
       <uses-feature android:name = "android.hardware.camera.autofocus" />
===Framework层===
android.hardware.Camera：代码位置/android/frameworks/base/core/java/android/hardware/Camera.java
这部分目标是framework.jar。这是Android 提供给app层调用的java接口。这个类用来连接或断开一个Camera 服务，设置拍摄参数，开始、停止预览，拍照等。
android.hardware.Camera这个类是和JNI中定义的类是一个，有些方法通过JNI的方式调用本地代码得到，有些方法自己实现。  
Camera的JAVA native调用部分（JNI）：/android/frameworks/base/core/jni /android_hardware_Camera.cpp。
Camera.java 承接JAVA 代码到C++ 代码的桥梁。编译生成libandroid_runtime.so 。
libandroid_runtime.so库是公用 的, 其中除了Camera 还有其他方面的功能。

===Camera框架的client部分===
代码位置：/android/frameworks/base/libs/camera/下5个文件。
      Camera.cpp
      CameraParameters.cpp
      ICamera.cpp
      ICameraClient.cpp
      ICameraService.cpp
它们的头文件在/android/frameworks/base/include/camera目录下。
这部分的内 容编译生成libcamera_client.so 。在Camera 模块的各个库中，libcamera_client.so 位于核心的位置，作为Camera 框架的 Client 客户端部分，与另外一部分内容服务端 libcameraservice.so 通过进程间通讯（即Binder 机制）的方式进行通讯。
===Camera框架的service部分===
代码位置：/android/frameworks/base/services/camera/libcameraservice。
这部分内容 被编译成库libcameraservice.so 。CameraService 是Camera 服务，Camera 框架的中间层，用于链接 CameraHardwareInterface 和Client部分 ，它通过调用实际的Camera 硬件接口来实现功能，即下层HAL层。


====摄像头预览、拍照、录像基本数据流向和处理流程以及驱动调试====

HAl层相关代码：（frameworks/base/services/camera/libcameraservice/CameraService.cpp）
      vendor/qcom/android-open/libcamera2/QualcommCameraHardware.cpp
      vendor/qcom/proprietary/mm-camera/apps/appslib/mm_camera_interface.c
      vendor/qcom/proprietary/mm-camera/apps/appslib/camframe.c
      vendor/qcom/proprietary/mm-camera/apps/appslib/snapshot.c
      vendor/qcom/proprietary/mm-camera/apps/appslib/jpeg_encoder.c
      vendor/qcom/proprietary/mm-camera/apps/appslib/cam_frame_q.c
      vendor/qcom/proprietary/mm-camera/apps/appslib/cam_display.c
      vendor/qcom/proprietary/mm-camera/targets/vfe31/8x60/
      vendor/qcom/proprietary/mm-camera/targets/vfe31/common/vpe1/QualcommCameraHardware.cpp
主要分为三个部分，preview，snapshot，video。它们分别用一个pthread进行处理。另外还有auto focus功能也是用pthread的方式处理。预览或拍照、视频线程处理得到的数据帧都以datacallback的方式回调到上层 CameraService.cpp中，进行存储或预览等操作。以下是HAL层部分的代码大概的调用结构流程。

cameraHAL层可分为两部分。一部分是 kernel层，负责模块的初始化，控制和数据流。
另一部分是vender层，它是framework与底层的驱动的接口。Vendor 层在初始化时会获取sensor 一些基本信息。 比如sensor 的 名称，是否支持3D 等。 同时把修改后的信息写回到用户空间。 Kernel 层初始化时，主要是初始化 I2C 接口、配置参数、check sensor ID。

===代码主要修改部分===
vendor/qcom/proprietary/mm-camera/mm-camera2/media-controller/modules/sensors/chromatix/0309/chromatix_s5k4h8/3A/文件夹下增加高通工具生成的效果代码。
vendor/qcom/proprietary/mm-camera/mm-camera2/media-controller/modules/sensors/sensor/libs/下增加或修改摄像头同名文件夹，xxx_lib.c.sensor_lib_ptr主要填充摄像头的初始化上点和下点代码。如果不写下电代码，默认是上点的反方向。
<code c>
static sensor_lib_t sensor_lib_ptr =
{
  .sensor_slave_info =
  {
    .sensor_name = SENSOR_MODEL,
    .slave_addr = 0x5A,
    .i2c_freq_mode = SENSOR_I2C_MODE_FAST,
    .addr_type = CAMERA_I2C_WORD_ADDR,
    .sensor_id_info =
    {
      .sensor_id_reg_addr = 0x0000,
      .sensor_id = 0x4088,
    },
    .power_setting_array =
    {
      .power_setting_a =
      {
        {
          .seq_type = CAMERA_POW_SEQ_GPIO,
          .seq_val = CAMERA_GPIO_STANDBY,
          .config_val = GPIO_OUT_LOW,
          .delay = 0,
        },
</code>                                                                                                                           

整个模块主要运行三个主线程：control、config及frame。
control用来执行总的控制，是上层控制接口。
      config主要进行一些配置，这个线程里面主要进行3A的工作，另外还有一些跟效果有关的设置；
      frame线程主要用来做帧queue的循环获取处理。所有事件或状态的反馈，用回调函数的方式传回QualcommCameraHardware.cpp。

====摄像头调试中的几个问题点====
    1、是否正确上电，是否有时钟波形输出。
     检测输出电压的电压值是否和上电时序以及MCLK是否符合sensor的要求。这部分可以用示波器和万用表测量。测量电压值和上电时序以及MCLK的时钟频率是否正确。
   2、 IIC读写是否正常。调试CPU与ISP间的I2C通信。
      检测包括IIC地址是否正确，协议是否匹配。这部分也可以用示波器测量IIC的SDA、CLK的峰值、波形逻辑是否正确。
    3、正确上电并初始化以后sensor模块是否正常工作。 
      这部分主要通过用示波器测量MIPI线路的数据和时钟PIN是否正确，它的波形是否含有数据，是否标准波形，峰值有没有达到要求等。
    4、如果以上都正确了以后，MIPI控制器将接收到中断，并开始处理图像信号。此时如果出错，可以通过中断信号的出错值查看错误状态。除CPU端是否正常初始 化工作的问题外，需要关注模组端设置的图像格式和CPU接收的默认图像格式和图像大小（SIZE）是否一致。模组中图片格式和图像大小通过寄存器值查看。
以上部分完成后，摄像头可以正确预览。

===附加知识===
1. chromatix,用于CAMERA ISP(qualcomm自己称呼为vfe(video front end)),用于raw sensor效果的,说白了就是手机摄像头效果的

2. 手机摄像头功能由多个功能模块组成，主要三 个部分，采集，加工，显示。 
     （1）采集部分由感光的 sensor 完成，通过 CAM IF 接口与手机芯片内的 CAM 连接。 
     （2）CAM 对 CAM IF 数据进行加工，主要是格式转换，特殊效果等。最终处理出来的一帧 数据，存在内存中。 
     （3） 手机的刷新线程，使用手机内部的 DMA 功能，或者 OVERLAY 技术，把处理好的 camera 图像，显示到 LCD 上。刷新部分，不在 camera 框架范围内。

3. 高通平台对于camera的代码组织，大体上还是遵循Android的框架：即上层应用和HAL层交互，高通平台在HAL层里面实现自己的一套管理策略； 在kernel中实现sensor的底层驱动。但是，对于最核心的sensor端的底层设置、ISP效果相关等代码则是单独进行了抽离，放在了一个 daemon进程中进行管理：
     由于高通把大部分具体的设置及参数放到了daemon进程中，所以在kernel部分只是进行了V4L2的设备注册、IIC设备注册等简单的动作。
     camera在kernel层的主文件为msm.c，负责设备的具体注册及相关方法的填 充；
     在msm_sensor.c文件中，主要维护高通自己的一个sensor相关结构体—msm_sensor_ctrl_t，同时把dts文件中的配置 信息读取出来；
     kernel层对于不同的sensor对应自己的一个驱动文件— xxsensor.c，主要是把power setting的设定填充到msm_sensor_ctrl_t中。    
     在vendor目录下，高通把各个sensor实质性的代码放置在此。一部分代码是高通自己实现的daemon进程和kernel层及HAL层进行通讯的 框架代码；
    另一部分则是和sensor相关的chromatix效果代码和sensor lib部分代码(init setting、lens info、output info)。
    高通平台通过一个函数指针数组sub_module_init来管理sensor相关的 组件；其中重要的是sensor_sub_module_init和chromatix_sub_module_init模块，对于sensor模块需要 对应填充sensor_lib_t下的接口，对于chromatix模块则是通过高通的chromatix工具生成。

4.术语
     CAM_VANA – 电源电压(模拟) 
     CAM_VDIG – 电源电压(数字) 
     CAM_VAF – 电源电压(致动器电压) 
     CAM_VIO – 输入/输出电压(数字)
5.cci(camera control interface)，即摄像头控制接口。
     由两部分组成，一是i2c ，而另一个部分是 gpio。也就是说，cci 包含i2c。一般情况下，我们只是用到了i2c 部分，没有用到gpio 部分。
     cci 在硬件上设计更加抽象，他使用命令的方式操作i2c，或 gpio， 而不是通常的寄存器方式。 这样的好处是对于一个硬件，我们使用的接口更加集中，硬件模块隐藏了具体的硬件细节。
     比如cci， 他就有i2c的命令队列，我们只是需要把相关的命令写到命令队列中就可了。 如果写一个终止命令，复位命令， 写命令， 然后开始执行， 这样的硬件实现了软件做的事情，驱动开发更加容易，也更加稳定，效率也更高。
     cci 还有一个队列是gpio的队列，往这个队列中写cmd，可以控制gpio的配置。
 --- //[[jinxin.liu@sim.com|jinxin.liu]] 2016/10/31 10:40//