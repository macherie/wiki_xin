a:109:{i:0;a:3:{i:0;s:14:"document_start";i:1;a:0:{}i:2;i:0;}i:1;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:0;}i:2;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:222:" 很多人对YUV数据格式不清楚，以至于在做视频的时候出现了一些不可预知的错误(比如说图像带有点、颜色不对等)。今晚是周末放假，我就抽点时间来给大家介绍一下。";}i:2;i:1;}i:3;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:224;}i:4;a:3:{i:0;s:12:"preformatted";i:1;a:1:{i:0;s:507:"     提示: 读下面的文字时，希望大家结合图片看，这样更易理解
     在YUV420中，一个像素点对应一个Y，一个2X2的小方块对应一个U和V。对于所有YUV420图像，它们的Y值排列是完全相同的，因为只有Y的图像就是灰度图像。YUV420sp与YUV420p的数据格式它们的UV排列在原理上是完全不同的。420p它是先把U存放完后，再存放V，也就是说UV它们是连续的。而420sp它是UV、UV这样交替存放的。(见下图)";}i:2;i:224;}i:5;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:224;}i:6;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:147:"有了上面的理论，我就可以准确的计算出一个YUV420在内存中存放的大小。
width * hight =Y（总和）
U = Y / 4  
V = Y / 4";}i:2;i:737;}i:7;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:884;}i:8;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:884;}i:9;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:68:"所以YUV420 数据在内存中的长度是 width * hight * 3 / 2，";}i:2;i:887;}i:10;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:955;}i:11;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:955;}i:12;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:24:"假设一个分辨率为";}i:2;i:957;}i:13;a:3:{i:0;s:14:"multiplyentity";i:1;a:2:{i:0;s:1:"8";i:1;s:1:"4";}i:2;i:981;}i:14;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:42:"的YUV图像，它们的格式如下图：";}i:2;i:984;}i:15;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1026;}i:16;a:3:{i:0;s:12:"preformatted";i:1;a:1:{i:0;s:121:"                   YUV420sp格式如下图                                                   YUV420p数据格式如下图";}i:2;i:1028;}i:17;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1028;}i:18;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:140:"有了上边的理论，我们可以对Android摄像头采集的YUV420sp数据做很多的转换，下面我写一个旋转90度的算法。";}i:2;i:1192;}i:19;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1332;}i:20;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1332;}i:21;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:15:"代码如下：";}i:2;i:1334;}i:22;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1349;}i:23;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1349;}i:24;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:21:"[java] view plaincopy";}i:2;i:1351;}i:25;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1373;}i:26;a:3:{i:0;s:12:"preformatted";i:1;a:1:{i:0;s:733:"  public static void rotateYUV240SP(byte[] src,byte[] des,int width,int height)  
      {  
           
          int wh = width * height;  
          //旋转Y  
          int k = 0;  
          for(int i=0;i<width;i++) {  
              for(int j=0;j<height;j++)   
              {  
                    des[k] = src[width*j + i];              
                    k++;  
              }  
          }  
            
          for(int i=0;i<width;i+=2) {  
              for(int j=0;j<height/2;j++)   
              {     
                    des[k] = src[wh+ width*j + i];      
                    des[k+1]=src[wh + width*j + i+1];  
                    k+=2;  
              }  
          }  
            
            
      }  ";}i:2;i:1373;}i:27;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1373;}i:28;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:21:"RGB Bayer Color分析";}i:2;i:2159;}i:29;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2180;}i:30;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2180;}i:31;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:198:"拜耳色彩滤波阵列（Bayer Color Filter Array，CFA）是非常有名的彩色图片的数字采集格式。色彩滤波器的模式如上图所示，由一半的G，1/4的R，1/4的B组成。";}i:2;i:2182;}i:32;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2380;}i:33;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2380;}i:34;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:119:"拜耳色彩滤波器的模式、序列、滤波器有很多种，但最常见的模式是由Kodak提出的2*2模式。";}i:2;i:2382;}i:35;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2501;}i:36;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2501;}i:37;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:69:"当Image Sensor往外逐行输出数据时，像素的序列为GRGRGR";}i:2;i:2514;}i:38;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:3:"...";}i:2;i:2583;}i:39;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:7:"/BGBGBG";}i:2;i:2586;}i:40;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:3:"...";}i:2;i:2593;}i:41;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:117:"（顺序RGB）。这样阵列的Sensor设计，使得RGB传感器减少到了全色传感器的1/3，如下所示。";}i:2;i:2596;}i:42;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2713;}i:43;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2713;}i:44;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:201:"图像传感器的结构如下所示，每一个感光像素之间都有金属隔离层，光纤通过显微镜头，在色彩滤波器过滤之后，投射到相应的漏洞式硅的感光元件上。";}i:2;i:2728;}i:45;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2929;}i:46;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2929;}i:47;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:34:"白平衡调节（White Balance）";}i:2;i:2935;}i:48;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2969;}i:49;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2969;}i:50;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:183:"色彩传感器并不能像人眼那样直接感应图像，因此为了保证最终图像的真实性，必须经过一些白平衡处理以及色彩校正等算法来修正图像。";}i:2;i:2971;}i:51;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3154;}i:52;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3154;}i:53;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:433:"原始像素的第一步处理操作就是白平衡调节。一个白色物体每通道的白平衡都应该是相同的，即R=G=B。通过白色物体的采集以及直方图分析，拥有最高级别白平衡的通道被作为目标通道，而其他两个通道通过增益达到匹配，如下：R'=aG'=bB'。同时，随着光源的不同，白平衡也应该相应的调节。
Bayer插值补偿算法（Bayer Interpolation）";}i:2;i:3156;}i:54;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3589;}i:55;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3589;}i:56;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:27:"1) 插值红蓝算法实现";}i:2;i:3591;}i:57;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3618;}i:58;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3618;}i:59;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:351:"每一个像素仅仅包括了光谱的一部分，必须通过插值来实现每个像素的RGB值。为了从Bayer格式得到每个像素的RGB格式，我们需要通过插值填补缺失的2个色彩。插值的方法有很多（包括领域、线性、3*3等），速度与质量权衡，最好的线性插值补偿算法。其中算法如下：";}i:2;i:3620;}i:60;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3971;}i:61;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3971;}i:62;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:83:"R和B通过线性领域插值，但这有四种不同的分布，如下图所示：";}i:2;i:3973;}i:63;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4056;}i:64;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4056;}i:65;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:20:"wps_clip_image-16029";}i:2;i:4058;}i:66;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4079;}i:67;a:3:{i:0;s:12:"preformatted";i:1;a:1:{i:0;s:59:"           （a）                                  （b）";}i:2;i:4079;}i:68;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4079;}i:69;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:17:"wps_clip_image-42";}i:2;i:4143;}i:70;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4161;}i:71;a:3:{i:0;s:12:"preformatted";i:1;a:1:{i:0;s:60:"         （c）                                     （d）";}i:2;i:4161;}i:72;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4161;}i:73;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:61:"在（a）与（b）中，R和B分别取领域的平均值。";}i:2;i:4226;}i:74;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4287;}i:75;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4287;}i:76;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:24:"2) 插值绿算法实现";}i:2;i:4289;}i:77;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4313;}i:78;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4313;}i:79;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:84:"在（c）与（d）中，取领域的4个B或R的均值作为中间像素的B值。";}i:2;i:4315;}i:80;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4399;}i:81;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4399;}i:82;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:20:"wps_clip_image-18476";}i:2;i:4401;}i:83;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4421;}i:84;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4421;}i:85;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:17:"（e）   （f）";}i:2;i:4423;}i:86;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4440;}i:87;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4440;}i:88;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:374:"由于人眼对绿光反应最敏感，对紫光和红光则反应较弱，因此为了达到更好的画质，需要对G特殊照顾。在上述（c）与（d）中，扩展开来就是上图的（e）与（f）中间像素G的取值，者也有一定的算法要求，不同的算法效果上会有差异。经过相关的研究，（e）中间像素G值的算法如下：";}i:2;i:4442;}i:89;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4816;}i:90;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4816;}i:91;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:5:"image";}i:2;i:4818;}i:92;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4823;}i:93;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4823;}i:94;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:41:"（f）中间像素G值的算法如下：";}i:2;i:4825;}i:95;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4866;}i:96;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4866;}i:97;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:5:"image";}i:2;i:4868;}i:98;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4873;}i:99;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4873;}i:100;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:543:"CMOS摄像头这部分转换是在内部用ADC或者ISP完成的，生产商为了降低成本必然会使得图像失真。当然用外部处理器来实现转换，如果处理器的速度足够NB，能够胜任像素的操作，用上面的算法来进行转换，皆大欢喜。不过上述算法将直接成倍提高了算法的复杂度，速度上将会有所限制。因此为了速度的提成，可以直接通过来4领域G取均值来中间像素的G值，将会降低一倍的速率，而在性能上差之甚微，算法如下：";}i:2;i:4875;}i:101;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:5418;}i:102;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:5418;}i:103;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:5:"image";}i:2;i:5420;}i:104;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:5425;}i:105;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:5425;}i:106;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:178:"如果能够通过损失图像的额质量，来达到更快的速度，还可以取G1、G2的均值来实现，但是这样的做法会导致边沿以及跳变部分的失真。";}i:2;i:5427;}i:107;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:5605;}i:108;a:3:{i:0;s:12:"document_end";i:1;a:0:{}i:2;i:5605;}}