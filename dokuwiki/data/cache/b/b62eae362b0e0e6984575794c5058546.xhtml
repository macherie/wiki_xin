
<p>
 很多人对YUV数据格式不清楚，以至于在做视频的时候出现了一些不可预知的错误(比如说图像带有点、颜色不对等)。今晚是周末放假，我就抽点时间来给大家介绍一下。
</p>
<pre class="code">     提示: 读下面的文字时，希望大家结合图片看，这样更易理解
     在YUV420中，一个像素点对应一个Y，一个2X2的小方块对应一个U和V。对于所有YUV420图像，它们的Y值排列是完全相同的，因为只有Y的图像就是灰度图像。YUV420sp与YUV420p的数据格式它们的UV排列在原理上是完全不同的。420p它是先把U存放完后，再存放V，也就是说UV它们是连续的。而420sp它是UV、UV这样交替存放的。(见下图)</pre>

<p>
有了上面的理论，我就可以准确的计算出一个YUV420在内存中存放的大小。
width * hight =Y（总和）
U = Y / 4  
V = Y / 4
</p>

<p>
所以YUV420 数据在内存中的长度是 width * hight * 3 / 2，
</p>

<p>
假设一个分辨率为8&times;4的YUV图像，它们的格式如下图：
</p>
<pre class="code">                   YUV420sp格式如下图                                                   YUV420p数据格式如下图</pre>

<p>
有了上边的理论，我们可以对Android摄像头采集的YUV420sp数据做很多的转换，下面我写一个旋转90度的算法。
</p>

<p>
代码如下：
</p>

<p>
[java] view plaincopy
</p>
<pre class="code">  public static void rotateYUV240SP(byte[] src,byte[] des,int width,int height)  
      {  
           
          int wh = width * height;  
          //旋转Y  
          int k = 0;  
          for(int i=0;i&lt;width;i++) {  
              for(int j=0;j&lt;height;j++)   
              {  
                    des[k] = src[width*j + i];              
                    k++;  
              }  
          }  
            
          for(int i=0;i&lt;width;i+=2) {  
              for(int j=0;j&lt;height/2;j++)   
              {     
                    des[k] = src[wh+ width*j + i];      
                    des[k+1]=src[wh + width*j + i+1];  
                    k+=2;  
              }  
          }  
            
            
      }  </pre>

<p>
RGB Bayer Color分析
</p>

<p>
拜耳色彩滤波阵列（Bayer Color Filter Array，CFA）是非常有名的彩色图片的数字采集格式。色彩滤波器的模式如上图所示，由一半的G，1/4的R，1/4的B组成。
</p>

<p>
拜耳色彩滤波器的模式、序列、滤波器有很多种，但最常见的模式是由Kodak提出的2*2模式。
</p>

<p>
当Image Sensor往外逐行输出数据时，像素的序列为GRGRGR…/BGBGBG…（顺序RGB）。这样阵列的Sensor设计，使得RGB传感器减少到了全色传感器的1/3，如下所示。
</p>

<p>
图像传感器的结构如下所示，每一个感光像素之间都有金属隔离层，光纤通过显微镜头，在色彩滤波器过滤之后，投射到相应的漏洞式硅的感光元件上。
</p>

<p>
白平衡调节（White Balance）
</p>

<p>
色彩传感器并不能像人眼那样直接感应图像，因此为了保证最终图像的真实性，必须经过一些白平衡处理以及色彩校正等算法来修正图像。
</p>

<p>
原始像素的第一步处理操作就是白平衡调节。一个白色物体每通道的白平衡都应该是相同的，即R=G=B。通过白色物体的采集以及直方图分析，拥有最高级别白平衡的通道被作为目标通道，而其他两个通道通过增益达到匹配，如下：R&#039;=aG&#039;=bB&#039;。同时，随着光源的不同，白平衡也应该相应的调节。
Bayer插值补偿算法（Bayer Interpolation）
</p>

<p>
1) 插值红蓝算法实现
</p>

<p>
每一个像素仅仅包括了光谱的一部分，必须通过插值来实现每个像素的RGB值。为了从Bayer格式得到每个像素的RGB格式，我们需要通过插值填补缺失的2个色彩。插值的方法有很多（包括领域、线性、3*3等），速度与质量权衡，最好的线性插值补偿算法。其中算法如下：
</p>

<p>
R和B通过线性领域插值，但这有四种不同的分布，如下图所示：
</p>

<p>
wps_clip_image-16029
</p>
<pre class="code">           （a）                                  （b）</pre>

<p>
wps_clip_image-42
</p>
<pre class="code">         （c）                                     （d）</pre>

<p>
在（a）与（b）中，R和B分别取领域的平均值。
</p>

<p>
2) 插值绿算法实现
</p>

<p>
在（c）与（d）中，取领域的4个B或R的均值作为中间像素的B值。
</p>

<p>
wps_clip_image-18476
</p>

<p>
（e）   （f）
</p>

<p>
由于人眼对绿光反应最敏感，对紫光和红光则反应较弱，因此为了达到更好的画质，需要对G特殊照顾。在上述（c）与（d）中，扩展开来就是上图的（e）与（f）中间像素G的取值，者也有一定的算法要求，不同的算法效果上会有差异。经过相关的研究，（e）中间像素G值的算法如下：
</p>

<p>
image
</p>

<p>
（f）中间像素G值的算法如下：
</p>

<p>
image
</p>

<p>
CMOS摄像头这部分转换是在内部用ADC或者ISP完成的，生产商为了降低成本必然会使得图像失真。当然用外部处理器来实现转换，如果处理器的速度足够NB，能够胜任像素的操作，用上面的算法来进行转换，皆大欢喜。不过上述算法将直接成倍提高了算法的复杂度，速度上将会有所限制。因此为了速度的提成，可以直接通过来4领域G取均值来中间像素的G值，将会降低一倍的速率，而在性能上差之甚微，算法如下：
</p>

<p>
image
</p>

<p>
如果能够通过损失图像的额质量，来达到更快的速度，还可以取G1、G2的均值来实现，但是这样的做法会导致边沿以及跳变部分的失真。
</p>
